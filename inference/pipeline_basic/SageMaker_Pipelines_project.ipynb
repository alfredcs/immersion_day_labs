{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Packages and Declare Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "region = sagemaker.Session().boto_region_name\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "sagemaker_session = sagemaker.session.Session(boto_session=boto_session, sagemaker_client=sm_client)\n",
    "\n",
    "#default_bucket = \"customer-churn-sm-pipeline\"\n",
    "default_bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker.Session().boto_region_name\n",
    "\n",
    "sklearn_processor_version=\"0.23-1\"\n",
    "model_package_group_name=\"ChurnModelPackageGroup\"\n",
    "pipeline_name= \"ChurnModelSMPipeline\"\n",
    "clarify_image = sagemaker.image_uris.retrieve(framework='sklearn',version=sklearn_processor_version,region=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate Baseline Dataset\n",
    "\n",
    "Baseline Data will be used as part of SageMaker Clarify Step to generate SHAP Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    ## Convert to datetime columns\n",
    "    df[\"firstorder\"]=pd.to_datetime(df[\"firstorder\"],errors='coerce')\n",
    "    df[\"lastorder\"] = pd.to_datetime(df[\"lastorder\"],errors='coerce')\n",
    "    ## Drop Rows with null values\n",
    "    df = df.dropna()\n",
    "    ## Create Column which gives the days between the last order and the first order\n",
    "    df[\"first_last_days_diff\"] = (df['lastorder']-df['firstorder']).dt.days\n",
    "    ## Create Column which gives the days between when the customer record was created and the first order\n",
    "    df['created'] = pd.to_datetime(df['created'])\n",
    "    df['created_first_days_diff']=(df['created']-df['firstorder']).dt.days\n",
    "    ## Drop Columns\n",
    "    df.drop(['custid','created','firstorder','lastorder'],axis=1,inplace=True)\n",
    "    ## Apply one hot encoding on favday and city columns\n",
    "    df = pd.get_dummies(df,prefix=['favday','city'],columns=['favday','city'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data = preprocess_data(\"data/storedata_total.csv\")\n",
    "baseline_data.pop(\"retained\")\n",
    "baseline_sample = baseline_data.sample(frac=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(baseline_sample).to_csv(\"data/baseline.csv\",header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Batch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = preprocess_data(\"data/storedata_total.csv\")\n",
    "batch_data.pop(\"retained\")\n",
    "batch_sample = batch_data.sample(frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(batch_sample).to_csv(\"data/batch.csv\",header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Copy Data and Scripts to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.resource('s3')\n",
    "s3_client.Bucket(default_bucket).upload_file(\"data/storedata_total.csv\",\"data/storedata_total.csv\")\n",
    "s3_client.Bucket(default_bucket).upload_file(\"data/batch.csv\",\"data/batch/batch.csv\")\n",
    "s3_client.Bucket(default_bucket).upload_file(\"data/baseline.csv\",\"input/baseline/baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.Bucket(default_bucket).upload_file(\"pipelines/customerchurn/preprocess.py\",\"input/code/preprocess.py\")\n",
    "s3_client.Bucket(default_bucket).upload_file(\"pipelines/customerchurn/evaluate.py\",\"input/code/evaluate.py\")\n",
    "s3_client.Bucket(default_bucket).upload_file(\"pipelines/customerchurn/generate_config.py\",\"input/code/generate_config.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Get the Pipeline Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.customerchurn.pipeline import get_pipeline\n",
    "\n",
    "pipeline = get_pipeline(\n",
    "    region = region,\n",
    "    role=role,\n",
    "    default_bucket=default_bucket,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    pipeline_name=pipeline_name,\n",
    "    custom_image_uri=clarify_image,\n",
    "    sklearn_processor_version=sklearn_processor_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Submit the pipeline to SageMaker and start execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we describe execution instance and list the steps in the execution to find out more about the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the execution steps to check out the status and artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
