{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: Working with the Online Store\n",
    "**This notebook uses the feature set and the XGBoost model created in `module-3`**\n",
    "\n",
    "**Note:** Please set kernel to `Python 3 (Data Science)` and set instance to `ml.t3.medium` (2x vCPU, 4GB)\n",
    "\n",
    "---\n",
    "\n",
    "# Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Create Feature Store helper functions](#Create-Feature-Store-helper-functions)\n",
    "1. [Fetch a single Customer record from the Online Feature Store](#Fetch-a-single-Customer-record-from-the-Online-Feature-Store)\n",
    "1. [Batch fetch multiple Product records from the Online Feature Store](#Batch-fetch-multiple-Product-records-from-the-Online-Feature-Store)\n",
    "1. [Real time inference using the deployed endpoint](#Real-time-inference-using-the-deployed-endpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a id='Background'></a>\n",
    "\n",
    "# Background\n",
    "\n",
    "In this notebook, we will learn how to extract the records stored in the online Customer and Products feature sets created in `Module-1`.\n",
    "We will then use the XGBoost model that was deployed to the endpoint in `Module-3`, making inference calls to it using the Customer and Product data we extracted from the feature store as parameters. \n",
    "Finally, we will then process the response from the XGBoost endpoint to determine if the customer should be offered a discount for each of the items in their basket.\n",
    "\n",
    "![Data Flow](../images/FS4_1.png \"Data Flow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Notes\n",
    "##### `This module depends on Modules 1, 2 and 3 being run first, as it uses the feature groups created in Module 1 and the endpoint created in Module 3.`\n",
    "##### In order to make this example simple, there is no \"Orders\" feature group to connect the Customer and the Products in a basket, as we would use in a real life scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a id='Setup'></a>\n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Upgrade to the latest version of the boto3 \n",
    "This ensures the `batch_get_record` API call is available for pulling multi records from feature store in a single operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "!pip install --upgrade boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import logging\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve endpoint and Feature Store group names from previous modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r customers_feature_group_name\n",
    "%store -r products_feature_group_name\n",
    "%store -r endpoint_name\n",
    "\n",
    "# give the endpoint a more meaningful name as we're using it for a different purpose here.\n",
    "discount_endpoint_name=endpoint_name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up SageMaker specific variables\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "sagemaker_runtime = boto_session.client('sagemaker-runtime') # for endpoint response\n",
    "sagemaker_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime') # used for FS fetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('__name__')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "logger.info(f'Using SageMaker version: {sagemaker.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a id='Create Feature Store helper functions'></a>\n",
    "\n",
    "# Create Feature Store helper functions\n",
    "##### These are a group of helper functions used to manipulate and fetch records from Feature Store.\n",
    "##### The primary function to be aware of is get_online_feature_group_records which calls the batch_get_record API call in the Feature Store SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert the record pulled back from the Feature Store to data of type dictionary.\n",
    "def _record_to_dict(rec, feature_types):\n",
    "    tmp_dict = {}\n",
    "    for f in rec:\n",
    "        feature_name = f['FeatureName']\n",
    "        string_feature_val = f['ValueAsString']\n",
    "        feature_type = feature_types[feature_name]\n",
    "        \n",
    "        if feature_type == 'Integral':\n",
    "            tmp_dict[f['FeatureName']] = int(string_feature_val)\n",
    "        elif feature_type == 'Fractional':\n",
    "            tmp_dict[f['FeatureName']] = float(string_feature_val)\n",
    "        else:\n",
    "            tmp_dict[f['FeatureName']] = string_feature_val\n",
    "\n",
    "    return tmp_dict\n",
    "\n",
    "\n",
    "def get_feature_definitions(fg_name):\n",
    "    fgdescription = sagemaker_client.describe_feature_group(FeatureGroupName=fg_name)    \n",
    "    return fgdescription \n",
    "\n",
    "\n",
    "def get_online_feature_group_records(fg_name, id_value_list):\n",
    "##### This function demonstrates how to get a batch of records in a single operation from the online feature store using batch_get_record.\n",
    "##### Previously we needed to call the getrecord API multiple times and manage parallelization of the API calls to achieve lower latency.\n",
    "##### Fetching a single record at a time is time consuming and increased operational complexity.\n",
    "##### To read multiple records from SageMaker Feature Store in a single, efficient API call, we'll use the batch_get_record() API call.\n",
    "    \n",
    "    feature_defs = get_feature_definitions(fg_name)['FeatureDefinitions']\n",
    "    feature_types = {}\n",
    "    feature_names = []\n",
    "    for fd in feature_defs:\n",
    "        feature_names.append(fd['FeatureName'])\n",
    "        feature_types[fd['FeatureName']] = fd['FeatureType']\n",
    "        \n",
    "    results = []\n",
    "    \n",
    "    identifiers = []\n",
    "    ids_list = []\n",
    "    for curr_id in id_value_list:\n",
    "        record_identifier_value = str(curr_id)\n",
    "        ids_list.append(record_identifier_value)\n",
    "    \n",
    "    identifiers.append({'FeatureGroupName': fg_name,\n",
    "                        'RecordIdentifiersValueAsString': ids_list,\n",
    "                        'FeatureNames': feature_names})\n",
    "        \n",
    "    resp = featurestore_runtime.batch_get_record(Identifiers=identifiers)\n",
    "    \n",
    "    for rec_dict in resp['Records']:\n",
    "        results.append(_record_to_dict(rec_dict['Record'], feature_types))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Count the number of items in a key-value pair dictionary record returned from the feature store\n",
    "def get_number_of_products_in_feature_set(dict):\n",
    "    record_count = 0\n",
    "    for i in enumerate(dict):\n",
    "        record_count += 1\n",
    "    return record_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a id='Fetch a single Customer record from the Online Feature Store'></a>\n",
    "\n",
    "# Fetch a single Customer record from the Online Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch details of the customer with the given ID from the Customer feature store group.\n",
    "# Here, it is used for a single Customer record fetch, but it will also be used later to fetch multiple Product records.\n",
    "customer_record = get_online_feature_group_records(customers_feature_group_name, ['C50'])\n",
    "\n",
    "\n",
    "# store the customer_id as we'll need it in the summary section\n",
    "customer_id=customer_record[0][\"customer_id\"]\n",
    "\n",
    "# convert the customer features to a list\n",
    "customer_values = customer_record[0].values() # get dict_values from customer \n",
    "\n",
    "# convert to list, eg: [0, 0, 0, 0, 0, 0, 1, 0, 0] - we'll append the product value to this next.\n",
    "# remove the customer_id and event_time values as they are not needed in the vector passed to the inference endpoint\n",
    "customer_features_list = list(customer_values)[1:3] + list(customer_values)[4:]\n",
    "#print(customer_features_list) # should be nine Customer features in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a id='Batch fetch multiple Product records from the Online Feature Store'></a>\n",
    "\n",
    "# Batch fetch multiple Product records from the Online Feature Store\n",
    "##### Fetch a list of randomly selected Products from the Products feature group created in module 1.\n",
    "##### Up to 100 records can be fetched from an online Feature Store in a single batch operation.\n",
    "##### For brevity, we will only fetch 10 Product records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_records = get_online_feature_group_records(products_feature_group_name, ['P256','P2','P6','P17','P28','P42','P71','P106','P242','P4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_records[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a id='Real time inference using the deployed endpoint'></a>\n",
    "\n",
    "# Real time inference using the deployed endpoint\n",
    "##### Now we will combine the vector of Customer features with a vector of Product features, one per Product in the customer basket.\n",
    "##### We will then pass the combined vector to the inference endpoint we created in Module 3, one call for each Product.\n",
    "##### The value returned from the inference call will determine if each Product in the Customer's basket should have a discount applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_payload = ''\n",
    "\n",
    "print('Customer ID is ' + customer_id)\n",
    "\n",
    "# Process the set of features for each Product in the Customer's basket\n",
    "products_in_basket_count = get_number_of_products_in_feature_set(product_records)\n",
    "\n",
    "# Now iterate through the Products record and combine the data for each product with that of the single Customer to whom the basket belongs.\n",
    "for i in range(products_in_basket_count):\n",
    "    \n",
    "    # store the product_id of the current Product record as we'll need it after the inference\n",
    "    product_id=product_records[i][\"product_id\"] \n",
    "    \n",
    "    # get feature values for this Product from the record retrived from Feature Store\n",
    "    product_values = product_records[i].values() \n",
    "    \n",
    "    # convert feature values to a list of product features, e.g.: [0, 0, 0, 0, 0, 0, 1, 0, .....,0]\n",
    "    # be sure to skip the first two features (product_id and event_time) since the model doesn't use them\n",
    "    product_features_list = list(product_values)[2:]    \n",
    "\n",
    "    # Concatenate the transformed Customer and Product parameter lists into a single 29 x 1 vector\n",
    "    inferencepayloadlist = customer_features_list + product_features_list\n",
    "\n",
    "    # convert the combined payload list into a string ready for inference\n",
    "    inferencepayloadstring=','.join([str(item) for item in inferencepayloadlist])\n",
    "    \n",
    "    # concatenate this payload onto the full multi-record payload, separating with a csv newline character\n",
    "    full_payload = full_payload + inferencepayloadstring + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the inference endpoint we created in module 3, passing all ten sets of Customer+Product parameters\n",
    "endpoint_response = sagemaker_runtime.invoke_endpoint(EndpointName=discount_endpoint_name, \n",
    "                                                      Body=full_payload, ContentType='text/csv') # , Accept='Accept') ##serializer(CSVSerializer), \n",
    "\n",
    "product_discount_ratings = endpoint_response['Body'].read().decode() # Response will be in the range 0.0 - 1.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_discount_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split out individual responses from endpoint\n",
    "ratings_list = product_discount_ratings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set an arbitrary discount value between 0 and 1.00\n",
    "discount_rating_threshold = 0.65\n",
    "\n",
    "# Display discount or standard pricing for each Product in the Customer's basket.\n",
    "for i in range(len(product_records)):\n",
    "    rating = float(ratings_list[i])\n",
    "    product_id = product_records[i]['product_id']\n",
    "    if rating < discount_rating_threshold:\n",
    "        print(f'   Product ID {product_id} discount rating = {rating:2.2f}: Standard list price.')\n",
    "    else:\n",
    "        print(f'   Product ID {product_id} discount rating = {rating:2.2f}: Offer discount or subscription to customer.')"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
