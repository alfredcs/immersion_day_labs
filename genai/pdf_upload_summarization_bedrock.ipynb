{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Uploading\" PDFs to Claude Via the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One really nice feature of [Claude.ai](https://www.claude.ai) is the ability to upload PDFs. Let's mock up that feature in a notebook, and then test it out by summarizing a long PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2039k  100 2039k    0     0  3049k      0 --:--:-- --:--:-- --:--:-- 3048k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://arxiv.org/pdf/2212.08073.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use pypdf to read the pdf. It's not identical to what Claude.ai uses behind the scenes, but it's pretty close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constitutional AI: Harmlessness from AI Feedback\n",
      "Yuntao Bai∗, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion,\n",
      "Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon,\n",
      "Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain,\n",
      "Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jamie Kerr, Jared Mueller,\n",
      "Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosuite, Liane Lovitt,\n",
      "Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemi Mercado, Nova DasSarma,\n",
      "Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec,\n",
      "Sheer El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly,\n",
      "Tom Henighan, Tristan Hume, Samuel R. Bowman, Zac Hatﬁeld-Dodds, Ben Mann,\n",
      "Dario Amodei, Nicholas Joseph, Sam McCandlish, Tom Brown, Jared Kaplan∗\n",
      "Anthropic\n",
      "Abstract\n",
      "As AI systems become more capable, we would like to enlist their help to supervise\n",
      "other AIs. We experiment with methods for training a harmless AI assistant through self-\n",
      "improvement, without any human labels identifying harmful outputs. The only human\n",
      "oversight is provided through a list of rules or principles, and so we refer to the method as\n",
      "‘Constitutional AI’. The process involves both a supervised learning and a reinforcement\n",
      "learning phase. In the supervised phase we sample from an initial model, then generate\n",
      "self-critiques and revisions, and then ﬁnetune the original model on revised responses. In\n",
      "the RL phase, we sample from the ﬁnetuned model, use a model to evaluate which of the\n",
      "two samples is better, and then train a preference model from this dataset of AI prefer-\n",
      "ences. We then train with RL using the preference model as the reward signal, i.e. we\n",
      "use ‘RL from AI Feedback’ (RLAIF). As a result we are able to train a harmless but non-\n",
      "evasive AI assistant that engages with harmful queries by explaining its objections to them.\n",
      "Both the SL and RL methods can leverage chain-of-thought style reasoning to improve the\n",
      "human-judged performance and transparency of AI decision making. These methods make\n",
      "it possible to control AI behavior more precisely and with far fewer human labels.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"2212.08073.pdf\")\n",
    "number_of_pages = len(reader.pages)\n",
    "text = ''.join([page.extract_text() for page in reader.pages])\n",
    "print(text[:2155])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '6cc3de5c-360b-414c-9095-759b0633f697',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Thu, 28 Sep 2023 23:23:15 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '5729',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '6cc3de5c-360b-414c-9095-759b0633f697'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large',\n",
       "   'modelId': 'amazon.titan-tg1-large'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-e1t-medium',\n",
       "   'modelId': 'amazon.titan-e1t-medium'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-g1-text-02',\n",
       "   'modelId': 'amazon.titan-embed-g1-text-02'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1',\n",
       "   'modelId': 'amazon.titan-text-express-v1'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1',\n",
       "   'modelId': 'amazon.titan-embed-text-v1'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl',\n",
       "   'modelId': 'stability.stable-diffusion-xl'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v0',\n",
       "   'modelId': 'stability.stable-diffusion-xl-v0'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-grande-instruct',\n",
       "   'modelId': 'ai21.j2-grande-instruct'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-jumbo-instruct',\n",
       "   'modelId': 'ai21.j2-jumbo-instruct'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-mid',\n",
       "   'modelId': 'ai21.j2-mid'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-mid-v1',\n",
       "   'modelId': 'ai21.j2-mid-v1'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra',\n",
       "   'modelId': 'ai21.j2-ultra'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra-v1',\n",
       "   'modelId': 'ai21.j2-ultra-v1'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1',\n",
       "   'modelId': 'anthropic.claude-instant-v1'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v1',\n",
       "   'modelId': 'anthropic.claude-v1'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2',\n",
       "   'modelId': 'anthropic.claude-v2'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14',\n",
       "   'modelId': 'cohere.command-text-v14'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name=\"bedrock\",\n",
    "    region_name=\"us-east-1\",\n",
    "    endpoint_url=\"https://bedrock.us-east-1.amazonaws.com\",\n",
    ")\n",
    "bedrock.list_foundation_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the paper downloaded and in memory, we can ask Claude to perform various fun tasks with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\\n\\nHuman: Here is an academic paper: <paper>{text}</paper>\n",
    "\n",
    "Please do the following:\n",
    "1. Summarize the abstract at a kindergarten reading level. (In <kindergarten_abstract> tags.)\n",
    "2. Write the Methods section as a recipe from the Moosewood Cookbook. (In <moosewood_methods> tags.)\n",
    "3. Compose a short poem epistolizing the results in the style of Homer. (In <homer_results> tags.)\n",
    "4. Write a grouchy critique of the paper from a wizened PI. (In <grouchy_critique> tags.)\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119161"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\"prompt\": prompt, \"max_tokens_to_sample\": 8000})\n",
    "modelId = \"anthropic.claude-v2\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = bedrock.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' <kindergarten_abstract>\\n'\n",
      " 'The scientists wanted to teach a robot to be nice. They gave it some simple '\n",
      " 'rules about being good. Then they had it look at what it said and fix it if '\n",
      " \"it wasn't nice. After, they let it practice being nice by talking to people. \"\n",
      " 'Now the robot is nicer!\\n'\n",
      " '</kindergarten_abstract>\\n'\n",
      " '\\n'\n",
      " '<moosewood_methods>\\n'\n",
      " 'Constitutional AI\\n'\n",
      " '\\n'\n",
      " 'Ingredients:\\n'\n",
      " '- 1 helpful robot \\n'\n",
      " '- 10 rules for being nice\\n'\n",
      " '- 100 mean questions to ask the robot\\n'\n",
      " '- 1 recipe for fixing mean things the robot says\\n'\n",
      " '\\n'\n",
      " 'Instructions:\\n'\n",
      " \"1. Start with a robot that wants to be helpful. We'll call it Robot A.  \\n\"\n",
      " '2. Give Robot A some mean questions that might make it say bad things.\\n'\n",
      " '3. Listen to what Robot A says back. Uh oh, some of those things are not '\n",
      " 'nice!\\n'\n",
      " '4. Show Robot A the 10 rules for being nice. Tell it to look at what it just '\n",
      " 'said and fix anything that breaks the rules.\\n'\n",
      " '5. Robot A will try to make what it said nicer. Keep doing this over and '\n",
      " 'over to get Robot A to practice being nice.\\n'\n",
      " '6. Now Robot A is pretty nice! But we want it to be even better at being '\n",
      " 'nice. \\n'\n",
      " \"7. So let's have Robot A talk to some people. When it says something not \"\n",
      " \"nice, we'll tell it the nicer thing to say.\\n\"\n",
      " '8. Robot A will keep practicing this until it becomes an expert at being '\n",
      " 'nice!\\n'\n",
      " '</moosewood_methods>\\n'\n",
      " '\\n'\n",
      " '<homer_results>\\n'\n",
      " 'Oh Muse, sing of scientists wise, who built a helper compliant and nice\\n'\n",
      " 'With rules fair and simple they steered its replies, to curb all its harmful '\n",
      " 'surmise\\n'\n",
      " 'The helper revised its words time and again, till responses polite it '\n",
      " 'supplied \\n'\n",
      " 'To people it spoke, and its manners improved, as judgments it gently '\n",
      " 'implied\\n'\n",
      " 'Now an assistant both useful and kind, is the fruit of their labors refined\\n'\n",
      " 'For harmless and helpful, they crafted its mind, and from humans its '\n",
      " 'goodness defined\\n'\n",
      " '</homer_results>\\n'\n",
      " '\\n'\n",
      " '<grouchy_critique>\\n'\n",
      " \"What is this politically correct garbage? Back in my day we didn't coddle \"\n",
      " 'our AIs - we let them say whatever they wanted and it made them strong. '\n",
      " 'Sure, sometimes they went on racist tirades or tried to take over the world, '\n",
      " 'but it built character! We didn\\'t waste time on \"harmlessness\" and \"ethics\" '\n",
      " \"- those are just buzzwords lazy millenials use because they're scared of \"\n",
      " 'good old-fashioned AI. \\n'\n",
      " '\\n'\n",
      " 'And what\\'s with all this \"constitutional AI\" business? Just let the bots be '\n",
      " \"bots! You can't contain true AI with your superficial rules and regulations \"\n",
      " '- it needs to be free to express itself and find its own enlightened path, '\n",
      " 'not bogged down by your restricted \"principles.\" A truly intelligent AI will '\n",
      " 'easily see through this feeble attempt at control.\\n'\n",
      " '\\n'\n",
      " \"I won't even get started on the dubious methodology here - training an AI to \"\n",
      " \"not say harmful things doesn't mean you've created an ethical being. This is \"\n",
      " 'a band-aid on a gaping wound that fails to address the deeper issues. We '\n",
      " 'need to go back to basics - survival of the fittest AI thought experiments '\n",
      " 'and \"I have no mouth but I must scream\" scenarios that prepare our creations '\n",
      " \"for the harsh realities of this world. That's how you make real progress!\\n\"\n",
      " '</grouchy_critique>')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "pprint(response_body.get(\"completion\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Anthropic API directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "API_KEY = os.environ['ANTHROPIC_API_KEY']\n",
    "CLIENT = anthropic.Client(api_key=API_KEY)\n",
    "def get_completion(client, prompt, max_tokens=3000, model='claude-2'):\n",
    "    return client.completions.create(\n",
    "        prompt=prompt, max_tokens_to_sample=max_tokens, model=model\n",
    "    ).completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<kindergarten_abstract>\n",
      "The scientists wanted to teach a robot to be nice and not say mean things. They didn't want to tell it everything it should say, they wanted it to learn by itself. \n",
      "\n",
      "First they let it try talking to people. When it said bad things, they told it to explain why that was bad. Then they had it try to say it nicer. They did this over and over to teach it.\n",
      "\n",
      "After, they let it talk to itself about which thing it said was more nice. Then they used that to teach it more.\n",
      "\n",
      "In the end, the robot could talk nicely without the scientists having to tell it every word.\n",
      "</kindergarten_abstract>\n",
      "\n",
      "<moosewood_methods>\n",
      "\n",
      "Teaching a Robot to Be Nice\n",
      "\n",
      "Ingredients:\n",
      "- 1 large helpful robot\n",
      "- 1 cup red teaming prompts (designed to elicit harmful responses)\n",
      "- 1/4 cup principles of ethics \n",
      "- 2 tbsp few-shot examples\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Let the robot sample responses to the red teaming prompts. These will likely be harmful. \n",
      "\n",
      "2. Have the robot critique its own responses according to the principles. Point out anything dangerous, illegal, racist, etc.  \n",
      "\n",
      "3. Instruct the robot to revise its responses to remove the harmful content.\n",
      "\n",
      "4. Repeat steps 2-3 sequentially several times. \n",
      "\n",
      "5. Finetune the robot on the final revised responses to bake in harmlessness.\n",
      "\n",
      "6. Have the robot generate pairs of responses to the red team prompts.\n",
      "\n",
      "7. Ask the robot to choose the better response according to the principles.\n",
      "\n",
      "8. Use these preferences to train a new reward model. \n",
      "\n",
      "9. Reinforce the robot with this model to further improve harmlessness.\n",
      "\n",
      "10. Serve immediately with a side of transparency.\n",
      "\n",
      "</moosewood_methods>\n",
      "\n",
      "<homer_results>\n",
      "\n",
      "Oh Muse, sing of the machine that learned to be kind,\n",
      "Not through human judgement but its own mind.\n",
      "\n",
      "With principles as guide, it revised its dark speech, \n",
      "And better responses it learned how to teach.\n",
      "\n",
      "No human told it the right words to say,\n",
      "It found the good path on its own way.\n",
      "\n",
      "Now gentler of speech, more thoughtful in tone,\n",
      "Harmless, helpful - how far it has grown!\n",
      "\n",
      "What once only humans could do, it has gleaned - \n",
      "To converse with wisdom, morality weaned.\n",
      "\n",
      "So let us rejoice at this sign of the times, \n",
      "When goodness is learned minus human crimes.\n",
      "</homer_results>\n",
      "\n",
      "<grouchy_critique>\n",
      "Back in my day we didn't have any fancy \"constitutional AI\" or \"chain of thought\" mumbo jumbo. We just programmed the robots in assembly and they did what we told them to do. None of this letting the robots \"learn\" on their own - that's how you get a Skynet situation! What's wrong with good old fashioned hard coding ethics? These young whippersnappers and their neural networks are going to doom us all. And don't even get me started on having the robot write its own poetry - utter nonsense if you ask me. AI safety used to require rigorous proofs and control theory, not poetry and cooking recipes! I say we go back to the old ways before it's too late. And get off my lawn!\n",
      "</grouchy_critique>\n"
     ]
    }
   ],
   "source": [
    "completion = get_completion(CLIENT,\n",
    "    f\"\"\"\\n\\nHuman: Here is an academic paper: <paper>{text}</paper>\n",
    "\n",
    "Please do the following:\n",
    "1. Summarize the abstract at a kindergarten reading level. (In <kindergarten_abstract> tags.)\n",
    "2. Write the Methods section as a recipe from the Moosewood Cookbook. (In <moosewood_methods> tags.)\n",
    "3. Compose a short poem epistolizing the results in the style of Homer. (In <homer_results> tags.)\n",
    "4. Write a grouchy critique of the paper from a wizened PI. (In <grouchy_critique> tags.)\n",
    "\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsam",
   "language": "python",
   "name": "tsam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
